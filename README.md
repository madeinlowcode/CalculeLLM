# ğŸ§® CalculeLLM - Calculadora de Custos de LLMs

<div align="center">

![CalculeLLM Banner](https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6)

**A ferramenta definitiva para desenvolvedores e empresas otimizarem seus gastos com IA**

[![React](https://img.shields.io/badge/React-19.1.1-61DAFB?style=flat&logo=react)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.8.2-3178C6?style=flat&logo=typescript)](https://www.typescriptlang.org/)
[![Vite](https://img.shields.io/badge/Vite-6.2.0-646CFF?style=flat&logo=vite)](https://vitejs.dev/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-Latest-38B2AC?style=flat&logo=tailwind-css)](https://tailwindcss.com/)

[ğŸš€ Demo ao Vivo](https://ai.studio/apps/drive/1FTXYo598CxVjW_iSV8-9bAxNdjxtNvPA) â€¢ [ğŸ“š DocumentaÃ§Ã£o](./docs/) â€¢ [ğŸ”— GitHub](https://github.com/madeinlowcode/CalculeLLM) â€¢ [ğŸ’¬ WhatsApp](https://chat.whatsapp.com/JAaqJzXz88f2K1WyOPXDdk)

</div>

## ğŸ“‹ Sobre o Projeto

O **CalculeLLM** Ã© uma aplicaÃ§Ã£o web moderna desenvolvida em React com TypeScript que permite calcular e comparar custos de diferentes modelos de Large Language Models (LLMs) em tempo real. Ideal para desenvolvedores, empresas e pesquisadores que precisam tomar decisÃµes baseadas em dados sobre o uso de IA.

### âœ¨ Principais Funcionalidades

- ğŸ”„ **ComparaÃ§Ã£o em Tempo Real**: Compare custos entre mÃºltiplos modelos de LLM simultaneamente
- ğŸ“Š **VisualizaÃ§Ã£o AvanÃ§ada**: GrÃ¡ficos interativos e dashboards intuitivos
- ğŸ’± **ConversÃ£o de Moeda**: Suporte a conversÃ£o USD/BRL com taxas personalizÃ¡veis
- â­ **Sistema de Favoritos**: Marque e organize seus modelos preferidos
- ğŸŒ“ **Tema Claro/Escuro**: Interface adaptÃ¡vel com preferÃªncias do usuÃ¡rio
- ğŸ“± **Design Responsivo**: Funciona perfeitamente em desktop, tablet e mobile
- ğŸ”„ **Dados Atualizados**: IntegraÃ§Ã£o com API OpenRouter para preÃ§os em tempo real
- ğŸ’¾ **PersistÃªncia Local**: Salva preferÃªncias no navegador

### ğŸ¯ Para Quem Ã© Este Projeto

- **Desenvolvedores**: Otimize custos de APIs de IA em seus projetos
- **Empresas**: Tome decisÃµes estratÃ©gicas sobre investimentos em IA
- **Pesquisadores**: Compare eficiÃªncia de custo entre diferentes modelos
- **Estudantes**: Aprenda sobre precificaÃ§Ã£o de modelos de linguagem

## ğŸš€ Quick Start

### PrÃ©-requisitos

- **Node.js** 18.0 ou superior
- **npm** 8.0 ou superior
- **Git** (para clonar o repositÃ³rio)

### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**
```bash
git clone https://github.com/madeinlowcode/CalculeLLM.git
cd CalculeLLM
```

2. **Instale as dependÃªncias**
```bash
npm install
```

3. **Configure variÃ¡veis de ambiente** (opcional)
```bash
# Crie o arquivo .env.local
echo "GEMINI_API_KEY=sua_chave_aqui" > .env.local
```

4. **Execute o projeto**
```bash
npm run dev
```

5. **Acesse a aplicaÃ§Ã£o**
```
http://localhost:5173
```

## ğŸ—ï¸ Arquitetura e Tecnologias

### Stack Principal
- **Frontend**: React 19.1.1 + TypeScript 5.8.2
- **Build Tool**: Vite 6.2.0
- **EstilizaÃ§Ã£o**: Tailwind CSS
- **GrÃ¡ficos**: Recharts 3.2.0
- **Fonte de Dados**: OpenRouter API

### Estrutura do Projeto
```
CalculeLLM/
â”œâ”€â”€ ğŸ“ components/           # Componentes React reutilizÃ¡veis
â”‚   â”œâ”€â”€ Header.tsx          # CabeÃ§alho com navegaÃ§Ã£o
â”‚   â”œâ”€â”€ ModelSelector.tsx   # SeleÃ§Ã£o de modelos
â”‚   â”œâ”€â”€ ResultsDisplay.tsx  # ExibiÃ§Ã£o de resultados
â”‚   â”œâ”€â”€ ComparisonChart.tsx # GrÃ¡fico de comparaÃ§Ã£o
â”‚   â””â”€â”€ icons/              # Ãcones SVG
â”œâ”€â”€ ğŸ“ docs/                # DocumentaÃ§Ã£o completa
â”œâ”€â”€ ğŸ“„ App.tsx              # Componente principal
â”œâ”€â”€ ğŸ“„ types.ts             # DefiniÃ§Ãµes TypeScript
â”œâ”€â”€ ğŸ“„ vite.config.ts       # ConfiguraÃ§Ãµes Vite
â””â”€â”€ ğŸ“„ package.json         # DependÃªncias e scripts
```

## ğŸ”§ Scripts DisponÃ­veis

```bash
# Desenvolvimento
npm run dev          # Inicia servidor de desenvolvimento

# ProduÃ§Ã£o
npm run build        # Gera build otimizado
npm run preview      # Preview do build local
```

## ğŸ“Š Funcionalidades Detalhadas

### ğŸ¯ SeleÃ§Ã£o de Modelos
- Busca e filtro por nome ou provedor
- Sistema de favoritos persistente
- InformaÃ§Ãµes detalhadas de cada modelo
- OrdenaÃ§Ã£o por custo ou popularidade

### ğŸ’° CÃ¡lculo de Custos
- Input personalizado de tokens (entrada/saÃ­da)
- CÃ¡lculo automÃ¡tico baseado em preÃ§os reais
- ComparaÃ§Ã£o lado a lado
- ProjeÃ§Ãµes para diferentes volumes

### ğŸ“ˆ VisualizaÃ§Ã£o de Dados
- GrÃ¡ficos de barras interativos
- Cards individuais por modelo
- Resumo estatÃ­stico
- Export de resultados

### âš™ï¸ ConfiguraÃ§Ãµes
- Taxa de conversÃ£o USD/BRL personalizÃ¡vel
- Tema claro/escuro
- Valores padrÃ£o configurÃ¡veis
- PersistÃªncia de preferÃªncias

## ğŸŒ IntegraÃ§Ãµes

### OpenRouter API
- **Endpoint**: `https://openrouter.ai/api/v1/models`
- **PropÃ³sito**: Dados atualizados de modelos e preÃ§os
- **FrequÃªncia**: AtualizaÃ§Ã£o a cada sessÃ£o
- **Filtros**: Modelos com contexto vÃ¡lido e preÃ§os disponÃ­veis

### Armazenamento Local
- **localStorage**: Favoritos e configuraÃ§Ãµes do usuÃ¡rio
- **SessÃ£o**: Estado temporÃ¡rio da aplicaÃ§Ã£o

## ğŸš€ Deploy e Hospedagem

### OpÃ§Ãµes de Deploy

#### 1. AI Studio (Atual)
```bash
# Deploy automÃ¡tico via Git
# URL: https://ai.studio/apps/drive/1FTXYo598CxVjW_iSV8-9bAxNdjxtNvPA
```

#### 2. Vercel
```bash
npm i -g vercel
vercel --prod
```

#### 3. Netlify
```bash
npm run build
netlify deploy --prod --dir=dist
```

#### 4. GitHub Pages
```yaml
# .github/workflows/deploy.yml incluÃ­do
```

### VariÃ¡veis de Ambiente

```bash
# ProduÃ§Ã£o
VITE_APP_ENV=production
GEMINI_API_KEY=sua_chave_gemini

# Desenvolvimento
VITE_APP_ENV=development
GEMINI_API_KEY=chave_desenvolvimento
```

## ğŸ“š DocumentaÃ§Ã£o Completa

Acesse a documentaÃ§Ã£o detalhada na pasta [`docs/`](./docs/):

- [ğŸ—ï¸ Arquitetura do Sistema](./docs/arquitetura.md)
- [ğŸ§© Componentes](./docs/componentes.md)
- [ğŸ“ OrganizaÃ§Ã£o de Pastas](./docs/organizacao-pastas.md)
- [ğŸ”— IntegraÃ§Ãµes](./docs/integracoes.md)
- [ğŸš€ Deploy](./docs/deploy.md)

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o sempre bem-vindas! Para contribuir:

1. **Fork** o projeto
2. Crie uma **branch** para sua feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. **Push** para a branch (`git push origin feature/AmazingFeature`)
5. Abra um **Pull Request**

### ğŸ“‹ Roadmap

- [ ] **v2.0**: Sistema de autenticaÃ§Ã£o
- [ ] **v2.1**: HistÃ³rico de cÃ¡lculos
- [ ] **v2.2**: API prÃ³pria para caching
- [ ] **v2.3**: Alertas de preÃ§os
- [ ] **v2.4**: RelatÃ³rios em PDF
- [ ] **v2.5**: IntegraÃ§Ã£o com mÃºltiplas APIs

## ğŸ› Reportar Bugs

Encontrou um bug? Abra uma [issue](https://github.com/madeinlowcode/CalculeLLM/issues) com:

- **DescriÃ§Ã£o** detalhada do problema
- **Passos** para reproduzir
- **Screenshots** (se aplicÃ¡vel)
- **Ambiente** (OS, browser, versÃ£o)

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ‘¥ Equipe

<div align="center">

**Desenvolvido com â¤ï¸ pela [Scrip7 Software](https://scrip7.com)**

CNPJ: 32.329.917/0001-20

[ğŸŒ Website](https://scrip7.com) â€¢ [ğŸ“§ Contato](mailto:contato@scrip7.com) â€¢ [ğŸ’¬ WhatsApp](https://chat.whatsapp.com/JAaqJzXz88f2K1WyOPXDdk)

</div>

## ğŸ™ Agradecimentos

- **OpenRouter** pelos dados de preÃ§os dos modelos
- **Google AI Studio** pela plataforma de deploy
- **Tailwind CSS** pelo sistema de design
- **Recharts** pelos componentes de grÃ¡ficos
- **Vite** pela ferramenta de build ultrarrÃ¡pida

---

<div align="center">

**â­ Se este projeto te ajudou, considere dar uma estrela no repositÃ³rio!**

[![GitHub stars](https://img.shields.io/github/stars/madeinlowcode/CalculeLLM?style=social)](https://github.com/madeinlowcode/CalculeLLM)

</div>